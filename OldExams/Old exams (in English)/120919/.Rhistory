# clean workspace:
graphics.off()
rm(list=ls())
# load the function for m shapiro test:
load("C:/Users/Marco Paggiaro/OneDrive/Desktop/mieidati/Applied Statistics/mcshapiro.test.RData")
# Import all the libraries:
library(class)
library(MASS)
library(car)
# data exploration:
data <- read.table("stress.txt", header = T)
head(data)
plot(data)
n <- dim(data)[1]
p <- dim(data)[2]
n1 <- 10
n2 <- 5
# a) 8 tests:
mod <- data[1:10,]
unmod <- data[11:15,]
T0 <- sapply(mod,median)-sapply(unmod,median)
T0
B <- 100000 # Number of permutations
T_stat <- numeric(B) # Vector where we will store the values of T*
# To estimate the p-value we use a loop
# Inside the loop, we do the following:
# 1. choose a random permutation of data (with the command sample)
# 2. calculate and save the test statistic obtained with the permuted data
for(perm in 1:B){
# permutation:
permutation <- sample(n)
x_perm <- data[permutation,]
x1_perm <- x_perm[1:n1,]
x2_perm <- x_perm[(n1+1):n,]
# test statistic:
T_stat[perm] <- sapply(x1_perm,median)-sapply(x2_perm,median)
}
# Permutational distribution of T
x11()
hist(T_stat,xlim=range(c(T_stat,T0)),breaks=30)
abline(v=T0,col=3,lwd=2)
plot(ecdf(T_stat))
abline(v=T0,col=3,lwd=2)
# p-value
p_val <- sum(T_stat>=T0)/B
p_val
T_stat
T_stat <- numeric(B,p) # Vector where we will store the values of T*
T_stat
help("numeric")
help("matrix")
T_stat <- matrix(B,p) # Vector where we will store the values of T*
T_stat
T_stat <- matrix(0,B,p) # Vector where we will store the values of T*
T_st
T_stat
set.seed(123)
B <- 100000 # Number of permutations
T_stat <- matrix(0,B,p) # Vector where we will store the values of T*
T1 <- T0
T1
T1 <- 2*T0
sum(T1 >= T0)
T_stat
# To estimate the p-value we use a loop
# Inside the loop, we do the following:
# 1. choose a random permutation of data (with the command sample)
# 2. calculate and save the test statistic obtained with the permuted data
for(perm in 1:B){
# permutation:
permutation <- sample(n)
x_perm <- data[permutation,]
x1_perm <- x_perm[1:n1,]
x2_perm <- x_perm[(n1+1):n,]
# test statistic:
T_stat[perm,] <- sapply(x1_perm,median)-sapply(x2_perm,median)
}
T_stat
# p-value
p_val <- numeric(p)
p_val[i] <- sum(T_stat[,i]>=T0)/B
# p-value
p_val <- numeric(p)
for (i in 1:p){
p_val[i] <- sum(T_stat[,i]>=T0)/B
}
p_val
debris<-read.table('debris.txt', header = T)
head(debris)
risk<-factor(debris[, c(3)], labels=c('L','H'))
stress<- read.table('stress.txt', header = T)
head(stress)
x1<-stress[1:10, ]
x2<-stress[11:15,]
#for each indicator
set.seed(123)
n1 <-10
n2<-5
n <- n1 + n2
Tstats<-rep(0,8)
pval<-rep(0,8)
for (i in 1:8){
# Test statistic: absolute difference between the two meedians
T0 <- median(x1[, i]) - median(x2[, i])
Tstats[i]<-T0
x_pooled <- c(x1[, i],x2[, i])
# CMC to estimate the p-value
B <- 100000 # Number of permutations
T_stat <- numeric(B) # Vector where we will store the values of T*
for(perm in 1:B){
# permutation:
permutation <- sample(1:n)
x_perm <- x_pooled[permutation]
x1_perm <- x_perm[1:n1]
x2_perm <- x_perm[(n1+1):n]
# test statistic:
T_stat[perm] <- median(x1_perm) - median(x2_perm)
}
# p-value
p_val <- sum(T_stat>=T0)/B
pval[i]<-p_val
}
Tstats
pval
p.fdr <- p.adjust(pval, 'fdr')
p.fdr
which(p.fdr < 0.25)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# clean workspace:
graphics.off()
rm(list=ls())
# load the function for m shapiro test:
load("C:/Users/Marco Paggiaro/OneDrive/Desktop/mieidati/Applied Statistics/mcshapiro.test.RData")
# Import all the libraries:
library(class)
library(MASS)
library(car)
# data exploration:
stress<- read.table('stress.txt', header = T)
head(stress)
x1<-stress[1:10, ]
x2<-stress[11:15,]
#for each indicator
set.seed(123)
n1 <-10
n2<-5
n <- n1 + n2
Tstats<-rep(0,8)
pval<-rep(0,8)
help (median)
median(x1)
median(x1[,1:10])
median(x1[,1:8])
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# clean workspace:
graphics.off()
rm(list=ls())
# load the function for m shapiro test:
load("C:/Users/Marco Paggiaro/OneDrive/Desktop/mieidati/Applied Statistics/mcshapiro.test.RData")
# Import all the libraries:
library(class)
library(MASS)
library(car)
# data exploration:
stress<- read.table('stress.txt', header = T)
head(stress)
x1<-stress[1:10, ]
x2<-stress[11:15,]
median(x1[,1])
median(x1[,1:8])
sapply(x1,median)
T0 <- sapply(x1, median) - sapply(x2,median)
pval<-rep(0,8)
T0
T0[1]
T0[1]-2
help("sapply")
T0 <- lapply(x1, median) - sapply(x2,median)
T0 <- vapply(x1, median) - sapply(x2,median)
T0 <- sapply(x1, median) - sapply(x2,median)
pval<-rep(0,8)
#for each indicator
set.seed(123)
n1 <-10
n2<-5
n <- n1 + n2
T0 <- sapply(x1, median) - sapply(x2,median)
pval<-rep(0,8)
for (i in 1:8){
# Test statistic: absolute difference between the two meedians
x_pooled <- c(x1[, i],x2[, i])
# CMC to estimate the p-value
B <- 10000 # Number of permutations
T_stat <- numeric(B) # Vector where we will store the values of T*
for(perm in 1:B){
# permutation:
permutation <- sample(n)
x_perm <- x_pooled[permutation]
x1_perm <- x_perm[1:n1]
x2_perm <- x_perm[(n1+1):n]
# test statistic:
T_stat[perm] <- median(x1_perm) - median(x2_perm)
}
# p-value
pval[i] <- sum(T_stat>=T0(i))/B
}
T0
T0 <- sapply(x1, median) - sapply(x2,median)
pval<-rep(0,8)
for (i in 1:8){
# Test statistic: absolute difference between the two meedians
x_pooled <- c(x1[, i],x2[, i])
# CMC to estimate the p-value
B <- 10000 # Number of permutations
T_stat <- numeric(B) # Vector where we will store the values of T*
for(perm in 1:B){
# permutation:
permutation <- sample(n)
x_perm <- x_pooled[permutation]
x1_perm <- x_perm[1:n1]
x2_perm <- x_perm[(n1+1):n]
# test statistic:
T_stat[perm] <- median(x1_perm) - median(x2_perm)
}
# p-value
pval[i] <- sum(T_stat>=T0[i])/B
}
T0
pval
p.fdr <- p.adjust(pval, 'fdr')
which(p.fdr < 0.25)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# clean workspace:
graphics.off()
rm(list=ls())
# load the function for m shapiro test:
load("C:/Users/Marco Paggiaro/OneDrive/Desktop/mieidati/Applied Statistics/mcshapiro.test.RData")
# Import all the libraries, just because
library(class)
library(MASS)
library(car)
sequoia <- read.table("sequoia.txt", header = T)
head(sequoia)
plot(sequo)
plot(sequoia)
# a) cluster analysis:
d = dist(sequoia)
clusts <- hclust(d, method='ward')
plot(clusts, hang=0, labels=FALSE, main='single', xlab='', sub='')
clusts <- hclust(d, method='ward.D2')
plot(clusts, hang=0, labels=FALSE, main='single', xlab='', sub='')
clusters <- cutree(clusts, k=5)
plot(sequoia, k=5)
plot(sequoia, col=clusters+2)
warnings()
plot(clusts, hang=0, labels=FALSE, main='Ward', xlab='', sub='')
clusters <- cutree(clusts, k=5)
plot(sequoia, col=clusters+2)
table(cutree)
table(clusters)
help aggregate()
? aggregate
list(clusters)
list(cluster = clusters)
clusters
centroids = aggregate(sequoia, clusters, centroids)
centroids = aggregate(sequoia, clusters, median)
centroids = aggregate(sequoia, list(clusters), median)
centroids
centroids = aggregate(sequoia, list(cluster=clusters), median)
centroids
points(centroids[,2:3])
centroids = aggregate(sequoia, list(cluster=clusters), medoid)
centroids = aggregate(sequoia, list(cluster=clusters), median)
centroids
centroids = aggregate(sequoia, list(cluster=clusters), mean)
centroids
centroids = aggregate(sequoia, list(cluster=clusters), median)
centroids
points(centroids[,2:3])
qchisq(0.01, 5)
qchisq(0.99, 5)
# mean and variance of the diameter of trees:
i1 = which(clusters == 1)
i2 = which(clusters == 2)
i3 = which(clusters == 3)
i4 = which(clusters == 4)
i5 = which(clusters == 5)
# assumption: Gaussianity of the groups.
table(clusters)
# assumption: Gaussianity of the groups.
table(clusters)[2,]
# assumption: Gaussianity of the groups.
table(clusters)[,2]
# assumption: Gaussianity of the groups.
t <- table(clusters)
# assumption: Gaussianity of the groups.
n <- table(clusters)
n[1]
n[1,1]
n1<-n[1]
# assumption: Gaussianity of the groups.
ng <- table(clusters)
sequoia
# Shapiro test on the variables:
for (i in 1:5){
shapiro.test(data[which(clusters == i),3])
}
data[i1,3]
shapiro.test(sequoia[which(clusters == i),3])
# Shapiro test on the variables:
for (i in 1:5){
shapiro.test(sequoia[which(clusters == i),3])
}
sequoia[i1]
sequoia[i1,]
sequoia[i1,3]
sequoia[i1,2]
# Shapiro test on the variables:
shapiro.test(sequoia[i1,2])
shapiro.test(sequoia[i2,2])
shapiro.test(sequoia[i3,2])
shapiro.test(sequoia[i4,2])
shapiro.test(sequoia[i5,2])
# assumption: Gaussianity of the groups.
n <- table(clusters)
# Shapiro test on the variables:
shapiro.test(sequoia[i1,2])
shapiro.test(sequoia[i2,2])
shapiro.test(sequoia[i3,2])
shapiro.test(sequoia[i4,2])
shapiro.test(sequoia[i5,2])
# mean: t-test
ICmean<-matrix(0, 5, 3)
ICvar<-matrix(0, 5, 3)
for (i in 1:5){
ICmean[i, ] <- cbind(inf=mean(sequoia[which(clusters==i),2]) - sqrt(var(sequoia[which(cluster == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1),
center= mean(sequoia[which(clusters==i),2]),
sup=mean(sequoia[which(clusters==i),2]) + sqrt(var(sequoia[which(cluster == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1))
ICvar[i, ] <- cbind(inf=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(1 - alpha/(2*k), n[i]-1),
center=var(sequoia[which(clusters == i), 2]),
sup=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(alpha/(2*k), n[i]-1))
}
# mean: t-test
ICmean<-matrix(0, 5, 3)
ICvar<-matrix(0, 5, 3)
for (i in 1:5){
ICmean[i, ] <- cbind(inf=mean(sequoia[which(clusters==i),2]) - sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1),
center= mean(sequoia[which(clusters==i),2]),
sup=mean(sequoia[which(clusters==i),2]) + sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1))
ICvar[i, ] <- cbind(inf=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(1 - alpha/(2*k), n[i]-1),
center=var(sequoia[which(clusters == i), 2]),
sup=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(alpha/(2*k), n[i]-1))
}
# b) Bonferroni CI's on mean and variance of clusters:
alpha <- 0.1
k <- 10 #ten CI's.
for (i in 1:5){
ICmean[i, ] <- cbind(inf=mean(sequoia[which(clusters==i),2]) - sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1),
center= mean(sequoia[which(clusters==i),2]),
sup=mean(sequoia[which(clusters==i),2]) + sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1))
ICvar[i, ] <- cbind(inf=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(1 - alpha/(2*k), n[i]-1),
center=var(sequoia[which(clusters == i), 2]),
sup=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(alpha/(2*k), n[i]-1))
}
ICmean
ICvar
data<-read.table('sequoia.txt', header = T)
head(data)
x11()
plot(data)
diss <- dist(data, method='euclidean')
dim(diss)
x11()
image(1:294,1:294,as.matrix(diss), main='metrics: Euclidean', asp=1, xlab='i', ylab='j')
clustw <- hclust(diss, method='ward.D2')
clustw
plot(clustw, main='Dendogram ward eucl', hang=-0.1, xlab='', labels=F, cex=0.6, sub='')
#rect.hclust(clustw, k=3)
#rect.hclust(clustw, k=4)
rect.hclust(clustw, k=5)
# Fix k=5 clusters:
cluster <- cutree(clustw, k=5) # i.e. euclidean-single:
cluster
table(cluster) #easy way to have numerosity of the 3 clusters
plot(data,main='k=5 wd', pch=16, col = as.vector(cluster)+1)
colMeans((data[which(cluster ==1), ]))
colMeans((data[which(cluster ==2), ]))
colMeans((data[which(cluster ==3), ]))
colMeans((data[which(cluster ==4), ]))
colMeans((data[which(cluster ==5), ]))
i1<- which(cluster ==1)
i2<- which(cluster ==2)
i3<- which(cluster ==3)
i4<- which(cluster ==4)
i5<- which(cluster ==5)
n1<-length(data[i1, 2])
n2<-length(data[i2, 2])
n3<-length(data[i3, 2])
n4<-length(data[i4, 2])
n5<-length(data[i5, 2])
n<-c(n1, n2, n3, n4, n5)
g<-5
p<-1
alpha<-0.1
k<- g*2
m<-rep(0, 5)
for (i in 1:5){
m[i] <- mean(data[which(cluster == i), 2])
}
#assumption gaussianity:
pval<-rep(0, 5)
for (i in 1:5){
pval[i] <- shapiro.test(data[which(cluster == i), 2])$p}
pval
#Bonf CI for each component
ICmean<-matrix(0, 5, 3)
ICvar<-matrix(0, 5, 3)
for (i in 1:5){
ICmean[i, ] <- cbind(inf=m[i] - sqrt(var(data[which(cluster == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1),
center= m[i],
sup= m[i] + sqrt(var(data[which(cluster == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1))
ICvar[i, ] <- cbind(inf=var(data[which(cluster == i), 2])*(n[i]-1) / qchisq(1 - alpha/(2*k), n[i]-1),
center=var(data[which(cluster == i), 2]),
sup=var(data[which(cluster == i), 2])*(n[i]-1) / qchisq(alpha/(2*k), n[i]-1))
}
ICmean
ICvar
# a) cluster analysis:
d = dist(sequoia)
clusts <- hclust(d, method='ward.D2')
plot(clusts, hang=0, labels=FALSE, main='Ward', xlab='', sub='')
clusters <- cutree(clusts, k=5)
plot(sequoia, col=clusters+2)
table(clusters)
centroids = aggregate(sequoia, list(cluster=clusters), median)
centroids
points(centroids[,2:3])
# b) Bonferroni CI's on mean and variance of clusters:
alpha <- 0.1
k <- 10 #ten CI's.
# mean and variance of the diameter of trees:
i1 = which(clusters == 1)
i2 = which(clusters == 2)
i3 = which(clusters == 3)
i4 = which(clusters == 4)
i5 = which(clusters == 5)
# assumption: Gaussianity of the groups.
n <- table(clusters)
# Shapiro test on the variables:
shapiro.test(sequoia[i1,2])
shapiro.test(sequoia[i2,2])
shapiro.test(sequoia[i3,2])
shapiro.test(sequoia[i4,2])
shapiro.test(sequoia[i5,2])
# mean: t-test
ICmean<-matrix(0, 5, 3)
ICvar<-matrix(0, 5, 3)
for (i in 1:5){
ICmean[i, ] <- cbind(inf=mean(sequoia[which(clusters==i),2]) - sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1),
center= mean(sequoia[which(clusters==i),2]),
sup=mean(sequoia[which(clusters==i),2]) + sqrt(var(sequoia[which(clusters == i), 2])/n[i]) * qt(1 - alpha/(2*k), n[i]-1))
ICvar[i, ] <- cbind(inf=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(1 - alpha/(2*k), n[i]-1),
center=var(sequoia[which(clusters == i), 2]),
sup=var(sequoia[which(clusters == i), 2])*(n[i]-1) / qchisq(alpha/(2*k), n[i]-1))
}
ICmean
ICvar
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# clean workspace:
graphics.off()
rm(list=ls())
# load the function for m shapiro test:
load("C:/Users/Marco Paggiaro/OneDrive/Desktop/mieidati/Applied Statistics/mcshapiro.test.RData")
# Import all the libraries, just because
library(class)
library(MASS)
library(car)
# a) classifier based on types of coordinates:
debris <- read.table("debris.txt", header = T)
head(debris)
attach(debris)
plot(x,y,col=risk)
plot(x,y, col=white)
points(data[which(risk=='H'),1:2], col='red' )
plot(x,y, col=white)
points(data[which(risk=='H'),1:2], col='red' )
plot(x,y, col='white')
points(data[which(risk=='H'),1:2], col='red' )
points(data[which(risk=="H"),1:2], col='red' )
points(debris[which(risk=="H"),1:2], col='red' )
points(debris[which(risk=="H"),1:2], col='green2')
points(debris[which(risk=="H"),1:2], col='red' )
points(debris[which(risk=="L"),1:2], col='green10')
points(debris[which(risk=="L"),1:2], col='green4')
View(mcshapiro.test)
View(mcshapiro.test)
View(mcshapiro.test)
# set wd
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# clean workspace:
graphics.off()
rm(list=ls())
